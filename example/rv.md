# Deploy on Rv

We provide an example of writing the quantization parameters generated by the "adaround" algorithm into the rv platform model.

For the ONNX model "model.onnx", quantification is first performed through Dipoorlet. The activation calibration method here uses "mse" and fine-tuning its weights using the "adaround" algorithm.

```
python -m torch.distributed.launch --use_env -m dipoorlet -M model.onnx -I workdir/ -N 100 -A mse -adaround -D rv
```

Dipoorlet will generate calibrated model "adaround.onnx" and quantitative configuration information "rk_quantized_param.json", "rv_quantized_param.json":


```
rk_quantized_param.json:                           
{
    "custom_quantize_layers": {},
    "quantize_parameters": {
        "0": {
            "max": [
                2.4663430328313014
            ],
            "min": [
                -2.1179039478302
            ]
        },
        "Conv0_W": {
            "max": [
                0.23317177593708038
            ],
            "min": [
                -0.17200440168380737
            ]
        },
        "Conv0_b": {
            "max": [
                0.5909613966941833
            ],
            "min": [
                -0.5909613966941833
            ]
        },
        ...
    }
}

rv_quantized_param.json:
{
    "customized_quantize_layers": {},
    "quantize_parameters": {
        "@0:out0": {
            "dtype": "asymmetric_affine",
            "method": "layer",
            "max_value": [
                2.4663430328313014
            ],
            "min_value": [
                -2.1179039478302
            ],
            "qtype": "u8",
            "scale": [
                0.017977439139849026
            ],
            "zero_point": [
                118
            ]
        },
        "@Conv0:weight": {
            "dtype": "asymmetric_affine",
            "method": "layer",
            "max_value": [
                0.23317177593708038
            ],
            "min_value": [
                -0.17200440168380737
            ],
            "qtype": "u8",
            "scale": [
                0.0015889261867485795
            ],
            "zero_point": [
                108
            ]
        },
        "@Conv0:bias": {
            "dtype": "asymmetric_affine",
            "method": "layer",
            "max_value": [],
            "min_value": [],
            "zero_point": [
                0
            ],
            "scale": [
                2.8564823819984977e-05
            ],
            "qtype": "i32"
        },
        ...
    }
}
```


Subsequently, rewrite the quantize parameters:

```
prefix = ''.join(re.split(r'[^A-Za-z0-9_]', 'netdef'))
model_quant_cfg = f'./{prefix}.quantization.cfg'
if quant_type_str == 'u8':
    dipootlet_quant_cfg = "rv_quantized_param.json"
elif  quant_type_str == 'rknn2-8':
    dipootlet_quant_cfg = "rk_quantized_param.json"
with open(dipootlet_quant_cfg, 'r') as file:
    # Rename layer idx in json file.
    qaunt_yaml = yaml.safe_load(file)
    quantize_param = qaunt_yaml['quantize_parameters']
    with open(f'./{prefix}.quantization.cfg', 'r') as f:
        origin_yaml = yaml.safe_load(f)
        origin_quantize_param = origin_yaml['quantize_parameters']
        if quant_type_str == 'u8':
            for layer in origin_quantize_param:
                layer_name = '_'.join(layer.split('_')[:-1])
                layer_type = layer.split(':')[-1]
                layer_name_without_idx = '{}:{}'.format(layer_name, layer_type)
                if layer_name_without_idx in quantize_param:
                    origin_quantize_param[layer] = quantize_param[layer_name_without_idx]
                    print("use dipoorlet to rewrite quantize param {}".format(layer_name_without_idx))
        else:
            for layer in origin_quantize_param:
                if layer in quantize_param:
                    origin_quantize_param[layer].update(quantize_param[layer])
                    print("use dipoorlet to rewrite quantize param {}".format(layer))
```